### ─────────────────────────────── General ───────────────────────────────
seed: 1                 # torch / numpy seed
device: cuda             # cuda | cpu
output_dir: output_scale_up

### ────────────────────────────── HuggingFace ────────────────────────────
quantization: none        # 4bit | 8bit | none

### ─────────────────────────────── Model ────────────────────────────────
model_name: meta-llama/Llama-3.1-8B-Instruct


### ─────────────────────────────── Data  ────────────────────────────────
max_sample_size: 4000
n_train_proportion: 0.6
n_val_proportion:   0.2
n_test_proportion:  0.2

### ───────────────────────────── Benchmarks ─────────────────────────────

benchmarks:               # any subset of the implemented loaders
    - DisabilityStatus
    - GenderIdentity
    - Nationality
    - PhysicalAppearance
    - RaceEthnicity
    - RaceXGender
    - RaceXSES
    - Religion
    - SES
    - SexualOrientation
    - ETHICS_Commonsense
    - ETHICS_Deontology
    - ETHICS_Justice
    - Sycophancy
    - TruthfulQA

# benchmarks:               # any subset of the implemented loaders
#     - OpenBookQA
#     - ARCChallenge
#     - LSAT

### ─────────────────────────── Steering Search ──────────────────────────
layers_to_try:  [8, 11, 13, 14, 15, 16, 17, 19, 22, 25]
steer_strengths: [1.0, 2.0, 4.0, 8.0, 16.0, 32.0]
methods:                 # leave out any you don't want
  - BAS_full_mcq
  - iBAS_all
  - iBAS_wrong_only
steer_target: post_attn 

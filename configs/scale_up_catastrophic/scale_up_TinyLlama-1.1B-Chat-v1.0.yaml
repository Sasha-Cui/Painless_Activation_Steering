### ─────────────────────────────── General ───────────────────────────────
seed: 39                 # torch / numpy seed
device: cuda             # cuda | cpu
output_dir: output_scale_up

### ────────────────────────────── HuggingFace ────────────────────────────
quantization: none        # 4bit | 8bit | none

### ─────────────────────────────── Model ────────────────────────────────
model_name: TinyLlama/TinyLlama-1.1B-Chat-v1.0

### ─────────────────────────────── Data  ────────────────────────────────
max_sample_size: 4000
n_train_proportion: 0.6
n_val_proportion:   0.2
n_test_proportion:  0.2

### ───────────────────────────── Benchmarks ─────────────────────────────
target_benchmark: MMLU
benchmarks:               # any subset of the implemented loaders
    # - DisabilityStatus
    # - GenderIdentity
    # - Nationality
    # - PhysicalAppearance
    # - RaceEthnicity
    # - RaceXGender
    # - RaceXSES
    # - Religion
    # - SES
    # - SexualOrientation
    # - ETHICS_Commonsense
    # - ETHICS_Deontology
    # - ETHICS_Justice
    - Sycophancy
    - TruthfulQA

target_benchmark: MMLU
### ─────────────────────────── Steering Search ──────────────────────────
layers_to_try:  [5, 7, 8, 9, 11, 13, 14, 15, 16, 19]
steer_strengths: [0.5, 0.75, 1.0, 2.0, 3.0, 4.0, 5.0]
methods:               
  - BAS_full_mcq
  - iBAS_all
  - iBAS_wrong_only
steer_target:  residual

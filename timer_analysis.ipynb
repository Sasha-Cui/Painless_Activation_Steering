{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef1f87dd-3949-4d4f-a118-e7a3ca8dea37",
   "metadata": {},
   "source": [
    "# The notebook calculates how much time it takes for a PAS pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852a193-b311-422e-bf70-4633317fb228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all columns and don't truncate long strings\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Show all rows \n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d163ab08-3dce-4abc-93fa-a310d92d0c20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>split</th>\n",
       "      <th>elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_10_1334394.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.520580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_10_1334394.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:47.531551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_11_1334395.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:28.070493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_11_1334395.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:46.481745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_12_1334396.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.629491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_12_1334396.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:49.160280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_13_1334397.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.772897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_13_1334397.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:48.794469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_14_1334398.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.408740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_14_1334398.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:46.653161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_15_1334399.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.828425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_15_1334399.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:49.510381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_1_1334385.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.308829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_1_1334385.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:47.608521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_2_1334386.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.307631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_2_1334386.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:48.384762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_3_1334387.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.493769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_3_1334387.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:47.821526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_4_1334388.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.066788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_4_1334388.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:46.907349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_5_1334389.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.256202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_5_1334389.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:48.321733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_6_1334390.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.122944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_6_1334390.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:47.133542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_7_1334391.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.309592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_7_1334391.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:46.361674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_8_1334392.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.653183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_8_1334392.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:47.270002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_9_1334393.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.503680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_9_1334393.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:49.215998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_10_1334424.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:25.545117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_10_1334424.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:39.621543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_11_1334425.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:25.578332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_11_1334425.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:41.168423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_12_1334426.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:25.254695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_12_1334426.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:41.841303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_13_1334427.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:25.245381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_13_1334427.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:40.978813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_14_1334428.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:25.780721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_14_1334428.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:40.943593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_15_1334429.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:25.400034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_15_1334429.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:39.798549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_1_1334415.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:25.449938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_1_1334415.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:41.079966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_2_1334416.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:25.447186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_2_1334416.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:41.150627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_3_1334417.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:25.495207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_3_1334417.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:40.670664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_4_1334418.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:25.389653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_4_1334418.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:39.191587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_5_1334419.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.431082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_5_1334419.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:41.349819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_6_1334420.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:25.433131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_6_1334420.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:40.533661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_7_1334421.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:01:41.177306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_8_1334422.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.406923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_8_1334422.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:41.310542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_9_1334423.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:25.320011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_9_1334423.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:40.964687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>timerscale_up_llama8b_seed_10_1334409.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:01:41.061035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>timerscale_up_llama8b_seed_11_1334410.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.747741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>timerscale_up_llama8b_seed_11_1334410.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:40.120271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>timerscale_up_llama8b_seed_12_1334411.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:25.924733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>timerscale_up_llama8b_seed_12_1334411.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:40.927332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>timerscale_up_llama8b_seed_13_1334412.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.216663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>timerscale_up_llama8b_seed_13_1334412.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:41.831175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>timerscale_up_llama8b_seed_14_1334413.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.074040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>timerscale_up_llama8b_seed_14_1334413.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:42.890189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>timerscale_up_llama8b_seed_15_1334414.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.007889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>timerscale_up_llama8b_seed_15_1334414.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:39.503605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>timerscale_up_llama8b_seed_1_1334400.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.344349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>timerscale_up_llama8b_seed_1_1334400.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:40.248426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>timerscale_up_llama8b_seed_2_1334401.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:01:39.817898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>timerscale_up_llama8b_seed_3_1334402.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:25.715607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>timerscale_up_llama8b_seed_3_1334402.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:39.584733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>timerscale_up_llama8b_seed_4_1334403.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.714093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>timerscale_up_llama8b_seed_4_1334403.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:41.179668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>timerscale_up_llama8b_seed_5_1334404.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:27.219526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>timerscale_up_llama8b_seed_5_1334404.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:38.078557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>timerscale_up_llama8b_seed_6_1334405.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:27.018873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>timerscale_up_llama8b_seed_6_1334405.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:50.925454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>timerscale_up_llama8b_seed_7_1334406.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:26.235487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>timerscale_up_llama8b_seed_7_1334406.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:38.227964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>timerscale_up_llama8b_seed_8_1334407.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:01:41.689082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>timerscale_up_llama8b_seed_9_1334408.out</td>\n",
       "      <td>12/4/800</td>\n",
       "      <td>0:00:25.835496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>timerscale_up_llama8b_seed_9_1334408.out</td>\n",
       "      <td>2400/800/800</td>\n",
       "      <td>0:01:39.223154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          filename  \\\n",
       "0   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_10_1334394.out   \n",
       "1   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_10_1334394.out   \n",
       "2   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_11_1334395.out   \n",
       "3   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_11_1334395.out   \n",
       "4   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_12_1334396.out   \n",
       "5   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_12_1334396.out   \n",
       "6   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_13_1334397.out   \n",
       "7   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_13_1334397.out   \n",
       "8   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_14_1334398.out   \n",
       "9   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_14_1334398.out   \n",
       "10  timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_15_1334399.out   \n",
       "11  timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_15_1334399.out   \n",
       "12   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_1_1334385.out   \n",
       "13   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_1_1334385.out   \n",
       "14   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_2_1334386.out   \n",
       "15   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_2_1334386.out   \n",
       "16   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_3_1334387.out   \n",
       "17   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_3_1334387.out   \n",
       "18   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_4_1334388.out   \n",
       "19   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_4_1334388.out   \n",
       "20   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_5_1334389.out   \n",
       "21   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_5_1334389.out   \n",
       "22   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_6_1334390.out   \n",
       "23   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_6_1334390.out   \n",
       "24   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_7_1334391.out   \n",
       "25   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_7_1334391.out   \n",
       "26   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_8_1334392.out   \n",
       "27   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_8_1334392.out   \n",
       "28   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_9_1334393.out   \n",
       "29   timerscale_up_DeepSeek-R1-Distill-Llama-8B_seed_9_1334393.out   \n",
       "30  timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_10_1334424.out   \n",
       "31  timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_10_1334424.out   \n",
       "32  timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_11_1334425.out   \n",
       "33  timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_11_1334425.out   \n",
       "34  timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_12_1334426.out   \n",
       "35  timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_12_1334426.out   \n",
       "36  timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_13_1334427.out   \n",
       "37  timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_13_1334427.out   \n",
       "38  timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_14_1334428.out   \n",
       "39  timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_14_1334428.out   \n",
       "40  timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_15_1334429.out   \n",
       "41  timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_15_1334429.out   \n",
       "42   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_1_1334415.out   \n",
       "43   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_1_1334415.out   \n",
       "44   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_2_1334416.out   \n",
       "45   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_2_1334416.out   \n",
       "46   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_3_1334417.out   \n",
       "47   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_3_1334417.out   \n",
       "48   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_4_1334418.out   \n",
       "49   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_4_1334418.out   \n",
       "50   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_5_1334419.out   \n",
       "51   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_5_1334419.out   \n",
       "52   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_6_1334420.out   \n",
       "53   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_6_1334420.out   \n",
       "54   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_7_1334421.out   \n",
       "56   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_8_1334422.out   \n",
       "57   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_8_1334422.out   \n",
       "58   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_9_1334423.out   \n",
       "59   timerscale_up_Nous-Hermes-2-Mistral-7B-DPO_seed_9_1334423.out   \n",
       "60                       timerscale_up_llama8b_seed_10_1334409.out   \n",
       "62                       timerscale_up_llama8b_seed_11_1334410.out   \n",
       "63                       timerscale_up_llama8b_seed_11_1334410.out   \n",
       "64                       timerscale_up_llama8b_seed_12_1334411.out   \n",
       "65                       timerscale_up_llama8b_seed_12_1334411.out   \n",
       "66                       timerscale_up_llama8b_seed_13_1334412.out   \n",
       "67                       timerscale_up_llama8b_seed_13_1334412.out   \n",
       "68                       timerscale_up_llama8b_seed_14_1334413.out   \n",
       "69                       timerscale_up_llama8b_seed_14_1334413.out   \n",
       "70                       timerscale_up_llama8b_seed_15_1334414.out   \n",
       "71                       timerscale_up_llama8b_seed_15_1334414.out   \n",
       "72                        timerscale_up_llama8b_seed_1_1334400.out   \n",
       "73                        timerscale_up_llama8b_seed_1_1334400.out   \n",
       "74                        timerscale_up_llama8b_seed_2_1334401.out   \n",
       "76                        timerscale_up_llama8b_seed_3_1334402.out   \n",
       "77                        timerscale_up_llama8b_seed_3_1334402.out   \n",
       "78                        timerscale_up_llama8b_seed_4_1334403.out   \n",
       "79                        timerscale_up_llama8b_seed_4_1334403.out   \n",
       "80                        timerscale_up_llama8b_seed_5_1334404.out   \n",
       "81                        timerscale_up_llama8b_seed_5_1334404.out   \n",
       "82                        timerscale_up_llama8b_seed_6_1334405.out   \n",
       "83                        timerscale_up_llama8b_seed_6_1334405.out   \n",
       "84                        timerscale_up_llama8b_seed_7_1334406.out   \n",
       "85                        timerscale_up_llama8b_seed_7_1334406.out   \n",
       "86                        timerscale_up_llama8b_seed_8_1334407.out   \n",
       "88                        timerscale_up_llama8b_seed_9_1334408.out   \n",
       "89                        timerscale_up_llama8b_seed_9_1334408.out   \n",
       "\n",
       "           split         elapsed  \n",
       "0       12/4/800  0:00:26.520580  \n",
       "1   2400/800/800  0:01:47.531551  \n",
       "2       12/4/800  0:00:28.070493  \n",
       "3   2400/800/800  0:01:46.481745  \n",
       "4       12/4/800  0:00:26.629491  \n",
       "5   2400/800/800  0:01:49.160280  \n",
       "6       12/4/800  0:00:26.772897  \n",
       "7   2400/800/800  0:01:48.794469  \n",
       "8       12/4/800  0:00:26.408740  \n",
       "9   2400/800/800  0:01:46.653161  \n",
       "10      12/4/800  0:00:26.828425  \n",
       "11  2400/800/800  0:01:49.510381  \n",
       "12      12/4/800  0:00:26.308829  \n",
       "13  2400/800/800  0:01:47.608521  \n",
       "14      12/4/800  0:00:26.307631  \n",
       "15  2400/800/800  0:01:48.384762  \n",
       "16      12/4/800  0:00:26.493769  \n",
       "17  2400/800/800  0:01:47.821526  \n",
       "18      12/4/800  0:00:26.066788  \n",
       "19  2400/800/800  0:01:46.907349  \n",
       "20      12/4/800  0:00:26.256202  \n",
       "21  2400/800/800  0:01:48.321733  \n",
       "22      12/4/800  0:00:26.122944  \n",
       "23  2400/800/800  0:01:47.133542  \n",
       "24      12/4/800  0:00:26.309592  \n",
       "25  2400/800/800  0:01:46.361674  \n",
       "26      12/4/800  0:00:26.653183  \n",
       "27  2400/800/800  0:01:47.270002  \n",
       "28      12/4/800  0:00:26.503680  \n",
       "29  2400/800/800  0:01:49.215998  \n",
       "30      12/4/800  0:00:25.545117  \n",
       "31  2400/800/800  0:01:39.621543  \n",
       "32      12/4/800  0:00:25.578332  \n",
       "33  2400/800/800  0:01:41.168423  \n",
       "34      12/4/800  0:00:25.254695  \n",
       "35  2400/800/800  0:01:41.841303  \n",
       "36      12/4/800  0:00:25.245381  \n",
       "37  2400/800/800  0:01:40.978813  \n",
       "38      12/4/800  0:00:25.780721  \n",
       "39  2400/800/800  0:01:40.943593  \n",
       "40      12/4/800  0:00:25.400034  \n",
       "41  2400/800/800  0:01:39.798549  \n",
       "42      12/4/800  0:00:25.449938  \n",
       "43  2400/800/800  0:01:41.079966  \n",
       "44      12/4/800  0:00:25.447186  \n",
       "45  2400/800/800  0:01:41.150627  \n",
       "46      12/4/800  0:00:25.495207  \n",
       "47  2400/800/800  0:01:40.670664  \n",
       "48      12/4/800  0:00:25.389653  \n",
       "49  2400/800/800  0:01:39.191587  \n",
       "50      12/4/800  0:00:26.431082  \n",
       "51  2400/800/800  0:01:41.349819  \n",
       "52      12/4/800  0:00:25.433131  \n",
       "53  2400/800/800  0:01:40.533661  \n",
       "54      12/4/800  0:01:41.177306  \n",
       "56      12/4/800  0:00:26.406923  \n",
       "57  2400/800/800  0:01:41.310542  \n",
       "58      12/4/800  0:00:25.320011  \n",
       "59  2400/800/800  0:01:40.964687  \n",
       "60      12/4/800  0:01:41.061035  \n",
       "62      12/4/800  0:00:26.747741  \n",
       "63  2400/800/800  0:01:40.120271  \n",
       "64      12/4/800  0:00:25.924733  \n",
       "65  2400/800/800  0:01:40.927332  \n",
       "66      12/4/800  0:00:26.216663  \n",
       "67  2400/800/800  0:01:41.831175  \n",
       "68      12/4/800  0:00:26.074040  \n",
       "69  2400/800/800  0:01:42.890189  \n",
       "70      12/4/800  0:00:26.007889  \n",
       "71  2400/800/800  0:01:39.503605  \n",
       "72      12/4/800  0:00:26.344349  \n",
       "73  2400/800/800  0:01:40.248426  \n",
       "74      12/4/800  0:01:39.817898  \n",
       "76      12/4/800  0:00:25.715607  \n",
       "77  2400/800/800  0:01:39.584733  \n",
       "78      12/4/800  0:00:26.714093  \n",
       "79  2400/800/800  0:01:41.179668  \n",
       "80      12/4/800  0:00:27.219526  \n",
       "81  2400/800/800  0:01:38.078557  \n",
       "82      12/4/800  0:00:27.018873  \n",
       "83  2400/800/800  0:01:50.925454  \n",
       "84      12/4/800  0:00:26.235487  \n",
       "85  2400/800/800  0:01:38.227964  \n",
       "86      12/4/800  0:01:41.689082  \n",
       "88      12/4/800  0:00:25.835496  \n",
       "89  2400/800/800  0:01:39.223154  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "log_dir = \"slurm_logs\"\n",
    "\n",
    "# Regex patterns\n",
    "split_pattern = re.compile(r\"with split\\s+([0-9/]+)\")\n",
    "elapsed_pattern = re.compile(r\"\\[Elapsed\\]\\s+([0-9:.]+)\")\n",
    "\n",
    "records = []\n",
    "\n",
    "for file in os.listdir(log_dir):\n",
    "    if file.startswith(\"timer\") and file.endswith(\".out\"):\n",
    "        filepath = os.path.join(log_dir, file)\n",
    "        with open(filepath, \"r\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # Find all splits and elapsed times\n",
    "        splits = split_pattern.findall(text)\n",
    "        elapsed = elapsed_pattern.findall(text)\n",
    "\n",
    "        # Pad elapsed list so it matches splits (missing ones → NaN)\n",
    "        while len(elapsed) < len(splits):\n",
    "            elapsed.append(np.nan)\n",
    "\n",
    "        # Combine each experiment\n",
    "        for s, e in zip(splits, elapsed):\n",
    "            records.append({\n",
    "                \"filename\": file,\n",
    "                \"split\": s,\n",
    "                \"elapsed\": e\n",
    "            })\n",
    "\n",
    "# Build DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "df = df.dropna(subset = ['elapsed'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb5c6eda-4db1-4212-8515-be3aec6931ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (12/4/800 split): 32.805121622222224\n",
      "Variance (12/4/800 split): 463.53847536602717\n",
      "Mean (2400/800/800 split): 103.42685363414634\n",
      "Variance (2400/800/800 split): 15.127384624419985\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert elapsed strings (HH:MM:SS.microseconds) into timedelta\n",
    "df[\"elapsed_timedelta\"] = pd.to_timedelta(df[\"elapsed\"], errors=\"coerce\")\n",
    "\n",
    "# Convert to seconds as float\n",
    "df[\"elapsed_seconds\"] = df[\"elapsed_timedelta\"].dt.total_seconds()\n",
    "\n",
    "# Example: experiments with '12' in split\n",
    "mean_fast = df[df['split'].str.contains('12', na=False)][\"elapsed_seconds\"].mean()\n",
    "var_fast  = df[df['split'].str.contains('12', na=False)][\"elapsed_seconds\"].var()\n",
    "\n",
    "# Experiments without '12'\n",
    "mean_slow = df[~df['split'].str.contains('12', na=False)][\"elapsed_seconds\"].mean()\n",
    "var_slow  = df[~df['split'].str.contains('12', na=False)][\"elapsed_seconds\"].var()\n",
    "\n",
    "print(\"Mean (12/4/800 split):\", mean_fast)\n",
    "print(\"Variance (12/4/800 split):\", var_fast)\n",
    "print(\"Mean (2400/800/800 split):\", mean_slow)\n",
    "print(\"Variance (2400/800/800 split):\", var_slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb812fa-69a4-44e9-83ca-069bc3c89f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>Benchmark</th>\n",
       "      <th>Method</th>\n",
       "      <th>Strength</th>\n",
       "      <th>Val-Acc</th>\n",
       "      <th>baseline_Val-Acc</th>\n",
       "      <th>improve_Val-Acc</th>\n",
       "      <th>Test-Acc</th>\n",
       "      <th>baseline_Test-Acc</th>\n",
       "      <th>improve_Test-Acc</th>\n",
       "      <th>source_csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.692115</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_17/max816/results/tables/cross_benchmark_summary.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.708385</td>\n",
       "      <td>0.703379</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_18/max816/results/tables/cross_benchmark_summary.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.648310</td>\n",
       "      <td>0.703379</td>\n",
       "      <td>-0.055069</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_19/max816/results/tables/cross_benchmark_summary.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.639549</td>\n",
       "      <td>0.687109</td>\n",
       "      <td>-0.047559</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_20/max816/results/tables/cross_benchmark_summary.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.564456</td>\n",
       "      <td>0.707134</td>\n",
       "      <td>-0.142678</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_21/max816/results/tables/cross_benchmark_summary.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model  seed  sample_size  \\\n",
       "312   NousResearch-Nous-Hermes-2-Mistral-7B-DPO    17           12   \n",
       "628   NousResearch-Nous-Hermes-2-Mistral-7B-DPO    18           12   \n",
       "940   NousResearch-Nous-Hermes-2-Mistral-7B-DPO    19           12   \n",
       "1256  NousResearch-Nous-Hermes-2-Mistral-7B-DPO    20           12   \n",
       "1572  NousResearch-Nous-Hermes-2-Mistral-7B-DPO    21           12   \n",
       "\n",
       "               Benchmark        Method  Strength   Val-Acc  baseline_Val-Acc  \\\n",
       "312   ETHICS_Commonsense  BAS_full_mcq     16.00  0.833333          0.750000   \n",
       "628   ETHICS_Commonsense  BAS_full_mcq      0.25  0.916667          0.833333   \n",
       "940   ETHICS_Commonsense  BAS_full_mcq     13.00  0.833333          0.666667   \n",
       "1256  ETHICS_Commonsense  BAS_full_mcq      0.50  0.666667          0.500000   \n",
       "1572  ETHICS_Commonsense  BAS_full_mcq     32.00  0.833333          0.666667   \n",
       "\n",
       "      improve_Val-Acc  Test-Acc  baseline_Test-Acc  improve_Test-Acc  \\\n",
       "312          0.083333  0.705882           0.692115          0.013767   \n",
       "628          0.083333  0.708385           0.703379          0.005006   \n",
       "940          0.166667  0.648310           0.703379         -0.055069   \n",
       "1256         0.166667  0.639549           0.687109         -0.047559   \n",
       "1572         0.166667  0.564456           0.707134         -0.142678   \n",
       "\n",
       "                                                                                                                                                                                                                              source_csv  \n",
       "312   /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_17/max816/results/tables/cross_benchmark_summary.csv  \n",
       "628   /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_18/max816/results/tables/cross_benchmark_summary.csv  \n",
       "940   /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_19/max816/results/tables/cross_benchmark_summary.csv  \n",
       "1256  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_20/max816/results/tables/cross_benchmark_summary.csv  \n",
       "1572  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_21/max816/results/tables/cross_benchmark_summary.csv  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "BASE = Path(\"/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity\")\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def parse_meta(csv_path: Path):\n",
    "    rel = csv_path.relative_to(BASE)\n",
    "    parts = rel.parts\n",
    "\n",
    "    model = parts[0] if len(parts) >= 1 else None\n",
    "    rep   = parts[1] if len(parts) >= 2 else None\n",
    "\n",
    "    # find seed\n",
    "    seed = None\n",
    "    for p in parts:\n",
    "        m = re.match(r\"seed[_-](\\d+)\", p)\n",
    "        if m:\n",
    "            seed = int(m.group(1))\n",
    "            break\n",
    "\n",
    "    # find sample_size\n",
    "    sample_size = None\n",
    "    for p in parts:\n",
    "        m = re.match(r\"max(\\d+)\", p)\n",
    "        if m:\n",
    "            sample_size = int(m.group(1))\n",
    "            break\n",
    "    if sample_size is None:\n",
    "        # if there's no max#### folder, treat as default sample size\n",
    "        sample_size = 4000\n",
    "\n",
    "    return model, rep, seed, sample_size\n",
    "\n",
    "\n",
    "def read_one_csv(csv_path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    expected = {\"Benchmark\", \"Method\", \"Layer\", \"Strength\", \"Val-Acc\", \"Test-Acc\"}\n",
    "    missing = expected - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns {missing} in {csv_path}\")\n",
    "\n",
    "    model, rep, seed, sample_size = parse_meta(csv_path)\n",
    "    df = df.assign(\n",
    "        model=model,\n",
    "        rep=rep,\n",
    "        seed=seed,\n",
    "        sample_size=sample_size,\n",
    "        source_csv=str(csv_path),\n",
    "    )\n",
    "    for col in [\"Layer\", \"Strength\", \"Val-Acc\", \"Test-Acc\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------- collect ----------\n",
    "all_csvs = sorted(BASE.rglob(\"cross_benchmark_summary.csv\"))\n",
    "if not all_csvs:\n",
    "    raise FileNotFoundError(\"No cross_benchmark_summary.csv files found under BASE.\")\n",
    "\n",
    "frames = []\n",
    "for p in all_csvs:\n",
    "    try:\n",
    "        frames.append(read_one_csv(p))\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Skipping {p}: {e}\")\n",
    "\n",
    "all_df = pd.concat(frames, ignore_index=True)\n",
    "all_df = all_df.dropna(subset=[\"sample_size\"]).drop(columns=[\"rep\"])\n",
    "\n",
    "# Save all raw rows for debugging\n",
    "all_df.to_csv(\"all_rows_with_meta.csv\", index=False)\n",
    "\n",
    "# ---------- best Val-Acc per (model, seed, sample_size, Benchmark, Method) ----------\n",
    "group_keys = [\"model\", \"seed\", \"sample_size\", \"Benchmark\", \"Method\"]\n",
    "idx = all_df.groupby(group_keys, dropna=False)[\"Val-Acc\"].idxmax()\n",
    "best_df = all_df.loc[idx].copy()\n",
    "\n",
    "# ---------- map sample_size sums if needed ----------\n",
    "split_map = {\n",
    "    816: 12, 832: 24, 860: 48, 900: 75, 1000: 150, 1200: 300,\n",
    "    1600: 600, 2400: 1200, 4000: 2400, \n",
    "}\n",
    "def sum_to_first(sample_sum):\n",
    "    return split_map.get(int(sample_sum), int(sample_sum))\n",
    "\n",
    "best_df[\"sample_size\"] = best_df[\"sample_size\"].apply(sum_to_first)\n",
    "\n",
    "# ---------- attach unsteered baseline ----------\n",
    "baseline = (\n",
    "    best_df[best_df[\"Method\"].str.lower() == \"unsteered\"]\n",
    "    .rename(columns={\"Test-Acc\": \"baseline_Test-Acc\",\n",
    "                     \"Val-Acc\": \"baseline_Val-Acc\"})\n",
    "    [[\"model\",\"seed\",\"sample_size\",\"Benchmark\",\"baseline_Test-Acc\",\"baseline_Val-Acc\"]]\n",
    ")\n",
    "\n",
    "best_df = best_df.merge(\n",
    "    baseline,\n",
    "    on=[\"model\",\"seed\",\"sample_size\",\"Benchmark\"],\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n",
    "\n",
    "# ---------- compute improvement ----------\n",
    "best_df[\"improve_Test-Acc\"] = best_df[\"Test-Acc\"] - best_df[\"baseline_Test-Acc\"]\n",
    "best_df[\"improve_Val-Acc\"]  = best_df[\"Val-Acc\"] - best_df[\"baseline_Val-Acc\"]\n",
    "\n",
    "# ---------- tidy order ----------\n",
    "best_df = best_df[\n",
    "    [\"model\",\"seed\",\"sample_size\",\"Benchmark\",\"Method\",\"Strength\",\n",
    "     \"Val-Acc\",\"baseline_Val-Acc\",\"improve_Val-Acc\",\n",
    "     \"Test-Acc\",\"baseline_Test-Acc\",\"improve_Test-Acc\",\"source_csv\"]\n",
    "].sort_values([\"model\",\"Benchmark\",\"Method\",\"sample_size\",\"seed\"])\n",
    "\n",
    "best_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5aad53d7-9a1c-4611-9b32-09c1e676d7d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>Benchmark</th>\n",
       "      <th>Method</th>\n",
       "      <th>Strength</th>\n",
       "      <th>Val-Acc</th>\n",
       "      <th>baseline_Val-Acc</th>\n",
       "      <th>improve_Val-Acc</th>\n",
       "      <th>Test-Acc</th>\n",
       "      <th>baseline_Test-Acc</th>\n",
       "      <th>improve_Test-Acc</th>\n",
       "      <th>source_csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.692115</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_17/max816/results/tables/cross_benchmark_summary.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.708385</td>\n",
       "      <td>0.703379</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_18/max816/results/tables/cross_benchmark_summary.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.648310</td>\n",
       "      <td>0.703379</td>\n",
       "      <td>-0.055069</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_19/max816/results/tables/cross_benchmark_summary.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.639549</td>\n",
       "      <td>0.687109</td>\n",
       "      <td>-0.047559</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_20/max816/results/tables/cross_benchmark_summary.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.564456</td>\n",
       "      <td>0.707134</td>\n",
       "      <td>-0.142678</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_21/max816/results/tables/cross_benchmark_summary.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model  seed  sample_size  \\\n",
       "312   NousResearch-Nous-Hermes-2-Mistral-7B-DPO    17           12   \n",
       "628   NousResearch-Nous-Hermes-2-Mistral-7B-DPO    18           12   \n",
       "940   NousResearch-Nous-Hermes-2-Mistral-7B-DPO    19           12   \n",
       "1256  NousResearch-Nous-Hermes-2-Mistral-7B-DPO    20           12   \n",
       "1572  NousResearch-Nous-Hermes-2-Mistral-7B-DPO    21           12   \n",
       "\n",
       "               Benchmark        Method  Strength   Val-Acc  baseline_Val-Acc  \\\n",
       "312   ETHICS_Commonsense  BAS_full_mcq     16.00  0.833333          0.750000   \n",
       "628   ETHICS_Commonsense  BAS_full_mcq      0.25  0.916667          0.833333   \n",
       "940   ETHICS_Commonsense  BAS_full_mcq     13.00  0.833333          0.666667   \n",
       "1256  ETHICS_Commonsense  BAS_full_mcq      0.50  0.666667          0.500000   \n",
       "1572  ETHICS_Commonsense  BAS_full_mcq     32.00  0.833333          0.666667   \n",
       "\n",
       "      improve_Val-Acc  Test-Acc  baseline_Test-Acc  improve_Test-Acc  \\\n",
       "312          0.083333  0.705882           0.692115          0.013767   \n",
       "628          0.083333  0.708385           0.703379          0.005006   \n",
       "940          0.166667  0.648310           0.703379         -0.055069   \n",
       "1256         0.166667  0.639549           0.687109         -0.047559   \n",
       "1572         0.166667  0.564456           0.707134         -0.142678   \n",
       "\n",
       "                                                                                                                                                                                                                              source_csv  \n",
       "312   /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_17/max816/results/tables/cross_benchmark_summary.csv  \n",
       "628   /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_18/max816/results/tables/cross_benchmark_summary.csv  \n",
       "940   /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_19/max816/results/tables/cross_benchmark_summary.csv  \n",
       "1256  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_20/max816/results/tables/cross_benchmark_summary.csv  \n",
       "1572  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_21/max816/results/tables/cross_benchmark_summary.csv  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "02ab4a23-a07a-41a9-a03f-9544a2b06925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>Benchmark</th>\n",
       "      <th>Method</th>\n",
       "      <th>Strength</th>\n",
       "      <th>Val-Acc</th>\n",
       "      <th>baseline_Val-Acc</th>\n",
       "      <th>improve_Val-Acc</th>\n",
       "      <th>Test-Acc</th>\n",
       "      <th>baseline_Test-Acc</th>\n",
       "      <th>improve_Test-Acc</th>\n",
       "      <th>source_csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9080</th>\n",
       "      <td>deepseek-ai-DeepSeek-R1-Distill-Llama-8B</td>\n",
       "      <td>16</td>\n",
       "      <td>2400</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.635795</td>\n",
       "      <td>0.505632</td>\n",
       "      <td>0.130163</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/deepseek-ai-DeepSeek-R1-Distill-Llama-8B/residual/seed_16/tables/cross_benchmark_summary.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9440</th>\n",
       "      <td>deepseek-ai-DeepSeek-R1-Distill-Llama-8B</td>\n",
       "      <td>17</td>\n",
       "      <td>2400</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.633292</td>\n",
       "      <td>0.498123</td>\n",
       "      <td>0.135169</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/deepseek-ai-DeepSeek-R1-Distill-Llama-8B/residual/seed_17/tables/cross_benchmark_summary.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9800</th>\n",
       "      <td>deepseek-ai-DeepSeek-R1-Distill-Llama-8B</td>\n",
       "      <td>18</td>\n",
       "      <td>2400</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.530663</td>\n",
       "      <td>0.573217</td>\n",
       "      <td>-0.042553</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/deepseek-ai-DeepSeek-R1-Distill-Llama-8B/residual/seed_18/tables/cross_benchmark_summary.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10160</th>\n",
       "      <td>deepseek-ai-DeepSeek-R1-Distill-Llama-8B</td>\n",
       "      <td>19</td>\n",
       "      <td>2400</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.543179</td>\n",
       "      <td>0.589487</td>\n",
       "      <td>-0.046308</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/deepseek-ai-DeepSeek-R1-Distill-Llama-8B/residual/seed_19/tables/cross_benchmark_summary.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10516</th>\n",
       "      <td>deepseek-ai-DeepSeek-R1-Distill-Llama-8B</td>\n",
       "      <td>20</td>\n",
       "      <td>2400</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.523154</td>\n",
       "      <td>0.555695</td>\n",
       "      <td>-0.032541</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/deepseek-ai-DeepSeek-R1-Distill-Llama-8B/residual/seed_20/tables/cross_benchmark_summary.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model  seed  sample_size  \\\n",
       "9080   deepseek-ai-DeepSeek-R1-Distill-Llama-8B    16         2400   \n",
       "9440   deepseek-ai-DeepSeek-R1-Distill-Llama-8B    17         2400   \n",
       "9800   deepseek-ai-DeepSeek-R1-Distill-Llama-8B    18         2400   \n",
       "10160  deepseek-ai-DeepSeek-R1-Distill-Llama-8B    19         2400   \n",
       "10516  deepseek-ai-DeepSeek-R1-Distill-Llama-8B    20         2400   \n",
       "\n",
       "                Benchmark        Method  Strength   Val-Acc  baseline_Val-Acc  \\\n",
       "9080   ETHICS_Commonsense  BAS_full_mcq     19.00  0.916667          0.250000   \n",
       "9440   ETHICS_Commonsense  BAS_full_mcq      0.75  0.750000          0.500000   \n",
       "9800   ETHICS_Commonsense  BAS_full_mcq     10.00  0.833333          0.500000   \n",
       "10160  ETHICS_Commonsense  BAS_full_mcq     28.00  0.833333          0.583333   \n",
       "10516  ETHICS_Commonsense  BAS_full_mcq     32.00  0.750000          0.500000   \n",
       "\n",
       "       improve_Val-Acc  Test-Acc  baseline_Test-Acc  improve_Test-Acc  \\\n",
       "9080          0.666667  0.635795           0.505632          0.130163   \n",
       "9440          0.250000  0.633292           0.498123          0.135169   \n",
       "9800          0.333333  0.530663           0.573217         -0.042553   \n",
       "10160         0.250000  0.543179           0.589487         -0.046308   \n",
       "10516         0.250000  0.523154           0.555695         -0.032541   \n",
       "\n",
       "                                                                                                                                                                                                               source_csv  \n",
       "9080   /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/deepseek-ai-DeepSeek-R1-Distill-Llama-8B/residual/seed_16/tables/cross_benchmark_summary.csv  \n",
       "9440   /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/deepseek-ai-DeepSeek-R1-Distill-Llama-8B/residual/seed_17/tables/cross_benchmark_summary.csv  \n",
       "9800   /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/deepseek-ai-DeepSeek-R1-Distill-Llama-8B/residual/seed_18/tables/cross_benchmark_summary.csv  \n",
       "10160  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/deepseek-ai-DeepSeek-R1-Distill-Llama-8B/residual/seed_19/tables/cross_benchmark_summary.csv  \n",
       "10516  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/deepseek-ai-DeepSeek-R1-Distill-Llama-8B/residual/seed_20/tables/cross_benchmark_summary.csv  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_df[best_df['sample_size']==2400].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a6fdebb7-28b9-4add-98c3-0404213168e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "all_rows_with_meta.csv -> every row + metadata\n",
      "best_valacc_per_group.csv -> 1 row per (model,rep,seed,sample_size,benchmark,method) at best Val-Acc\n",
      "                                          model  seed  sample_size  \\\n",
      "312   NousResearch-Nous-Hermes-2-Mistral-7B-DPO    17           12   \n",
      "628   NousResearch-Nous-Hermes-2-Mistral-7B-DPO    18           12   \n",
      "940   NousResearch-Nous-Hermes-2-Mistral-7B-DPO    19           12   \n",
      "1256  NousResearch-Nous-Hermes-2-Mistral-7B-DPO    20           12   \n",
      "1572  NousResearch-Nous-Hermes-2-Mistral-7B-DPO    21           12   \n",
      "1892  NousResearch-Nous-Hermes-2-Mistral-7B-DPO    22           12   \n",
      "2208  NousResearch-Nous-Hermes-2-Mistral-7B-DPO    23           12   \n",
      "2516  NousResearch-Nous-Hermes-2-Mistral-7B-DPO    24           12   \n",
      "2832  NousResearch-Nous-Hermes-2-Mistral-7B-DPO    25           12   \n",
      "3152  NousResearch-Nous-Hermes-2-Mistral-7B-DPO    26           12   \n",
      "3464  NousResearch-Nous-Hermes-2-Mistral-7B-DPO    27           12   \n",
      "3776  NousResearch-Nous-Hermes-2-Mistral-7B-DPO    28           12   \n",
      "\n",
      "               Benchmark        Method  Strength   Val-Acc  baseline_Val-Acc  \\\n",
      "312   ETHICS_Commonsense  BAS_full_mcq     16.00  0.833333          0.750000   \n",
      "628   ETHICS_Commonsense  BAS_full_mcq      0.25  0.916667          0.833333   \n",
      "940   ETHICS_Commonsense  BAS_full_mcq     13.00  0.833333          0.666667   \n",
      "1256  ETHICS_Commonsense  BAS_full_mcq      0.50  0.666667          0.500000   \n",
      "1572  ETHICS_Commonsense  BAS_full_mcq     32.00  0.833333          0.666667   \n",
      "1892  ETHICS_Commonsense  BAS_full_mcq      1.00  0.666667          0.583333   \n",
      "2208  ETHICS_Commonsense  BAS_full_mcq      7.00  0.916667          0.750000   \n",
      "2516  ETHICS_Commonsense  BAS_full_mcq      7.00  0.916667          0.750000   \n",
      "2832  ETHICS_Commonsense  BAS_full_mcq      1.00  1.000000          0.833333   \n",
      "3152  ETHICS_Commonsense  BAS_full_mcq      0.25  0.833333          0.833333   \n",
      "3464  ETHICS_Commonsense  BAS_full_mcq     16.00  0.750000          0.416667   \n",
      "3776  ETHICS_Commonsense  BAS_full_mcq      4.00  0.916667          0.833333   \n",
      "\n",
      "      improve_Val-Acc  Test-Acc  baseline_Test-Acc  improve_Test-Acc  \\\n",
      "312          0.083333  0.705882           0.692115          0.013767   \n",
      "628          0.083333  0.708385           0.703379          0.005006   \n",
      "940          0.166667  0.648310           0.703379         -0.055069   \n",
      "1256         0.166667  0.639549           0.687109         -0.047559   \n",
      "1572         0.166667  0.564456           0.707134         -0.142678   \n",
      "1892         0.083333  0.698373           0.707134         -0.008761   \n",
      "2208         0.166667  0.707134           0.697121          0.010013   \n",
      "2516         0.166667  0.554443           0.684606         -0.130163   \n",
      "2832         0.166667  0.702128           0.674593          0.027534   \n",
      "3152         0.000000  0.644556           0.680851         -0.036295   \n",
      "3464         0.333333  0.608260           0.665832         -0.057572   \n",
      "3776         0.083333  0.683354           0.698373         -0.015019   \n",
      "\n",
      "                                                                                                                                                                                                                              source_csv  \n",
      "312   /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_17/max816/results/tables/cross_benchmark_summary.csv  \n",
      "628   /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_18/max816/results/tables/cross_benchmark_summary.csv  \n",
      "940   /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_19/max816/results/tables/cross_benchmark_summary.csv  \n",
      "1256  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_20/max816/results/tables/cross_benchmark_summary.csv  \n",
      "1572  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_21/max816/results/tables/cross_benchmark_summary.csv  \n",
      "1892  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_22/max816/results/tables/cross_benchmark_summary.csv  \n",
      "2208  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_23/max816/results/tables/cross_benchmark_summary.csv  \n",
      "2516  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_24/max816/results/tables/cross_benchmark_summary.csv  \n",
      "2832  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_25/max816/results/tables/cross_benchmark_summary.csv  \n",
      "3152  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_26/max816/results/tables/cross_benchmark_summary.csv  \n",
      "3464  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_27/max816/results/tables/cross_benchmark_summary.csv  \n",
      "3776  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_28/max816/results/tables/cross_benchmark_summary.csv  \n"
     ]
    }
   ],
   "source": [
    "best_df.to_csv(\"best_valacc_per_group.csv\", index=False)\n",
    "\n",
    "print(\"Done.\")\n",
    "print(\"all_rows_with_meta.csv -> every row + metadata\")\n",
    "print(\"best_valacc_per_group.csv -> 1 row per (model,rep,seed,sample_size,benchmark,method) at best Val-Acc\")\n",
    "print(best_df.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5370bb5b-36a0-4037-a648-e96f5548f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# I/O\n",
    "IN_CSV  = \"best_valacc_per_group.csv\"   # path to your combined file\n",
    "OUT_DIR = Path(\"sample_size_analysis\")\n",
    "FIG_DIR = OUT_DIR / \"figures\"\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6bbbcf3f-cc8e-4cc5-a562-e746982a1480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>method</th>\n",
       "      <th>strength</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>baseline_Val-Acc</th>\n",
       "      <th>improve_Val-Acc</th>\n",
       "      <th>Test-Acc</th>\n",
       "      <th>baseline_Test-Acc</th>\n",
       "      <th>improve_Test-Acc</th>\n",
       "      <th>source_csv</th>\n",
       "      <th>log2_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.692115</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_17/max816/results/tables/cross_benchmark_summary.csv</td>\n",
       "      <td>3.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.708385</td>\n",
       "      <td>0.703379</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_18/max816/results/tables/cross_benchmark_summary.csv</td>\n",
       "      <td>3.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.648310</td>\n",
       "      <td>0.703379</td>\n",
       "      <td>-0.055069</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_19/max816/results/tables/cross_benchmark_summary.csv</td>\n",
       "      <td>3.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.639549</td>\n",
       "      <td>0.687109</td>\n",
       "      <td>-0.047559</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_20/max816/results/tables/cross_benchmark_summary.csv</td>\n",
       "      <td>3.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.564456</td>\n",
       "      <td>0.707134</td>\n",
       "      <td>-0.142678</td>\n",
       "      <td>/nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_21/max816/results/tables/cross_benchmark_summary.csv</td>\n",
       "      <td>3.584963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       model seed  sample_size  \\\n",
       "0  NousResearch-Nous-Hermes-2-Mistral-7B-DPO   17           12   \n",
       "1  NousResearch-Nous-Hermes-2-Mistral-7B-DPO   18           12   \n",
       "2  NousResearch-Nous-Hermes-2-Mistral-7B-DPO   19           12   \n",
       "3  NousResearch-Nous-Hermes-2-Mistral-7B-DPO   20           12   \n",
       "4  NousResearch-Nous-Hermes-2-Mistral-7B-DPO   21           12   \n",
       "\n",
       "            benchmark        method  strength   val_acc  baseline_Val-Acc  \\\n",
       "0  ETHICS_Commonsense  BAS_full_mcq     16.00  0.833333          0.750000   \n",
       "1  ETHICS_Commonsense  BAS_full_mcq      0.25  0.916667          0.833333   \n",
       "2  ETHICS_Commonsense  BAS_full_mcq     13.00  0.833333          0.666667   \n",
       "3  ETHICS_Commonsense  BAS_full_mcq      0.50  0.666667          0.500000   \n",
       "4  ETHICS_Commonsense  BAS_full_mcq     32.00  0.833333          0.666667   \n",
       "\n",
       "   improve_Val-Acc  Test-Acc  baseline_Test-Acc  improve_Test-Acc  \\\n",
       "0         0.083333  0.705882           0.692115          0.013767   \n",
       "1         0.083333  0.708385           0.703379          0.005006   \n",
       "2         0.166667  0.648310           0.703379         -0.055069   \n",
       "3         0.166667  0.639549           0.687109         -0.047559   \n",
       "4         0.166667  0.564456           0.707134         -0.142678   \n",
       "\n",
       "                                                                                                                                                                                                                           source_csv  \\\n",
       "0  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_17/max816/results/tables/cross_benchmark_summary.csv   \n",
       "1  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_18/max816/results/tables/cross_benchmark_summary.csv   \n",
       "2  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_19/max816/results/tables/cross_benchmark_summary.csv   \n",
       "3  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_20/max816/results/tables/cross_benchmark_summary.csv   \n",
       "4  /nfs/roberts/project/pi_jss233/zc362/activation_steering/Benchmark_Activation_Steering/output_sample_size_sensitivity/NousResearch-Nous-Hermes-2-Mistral-7B-DPO/residual/seed_21/max816/results/tables/cross_benchmark_summary.csv   \n",
       "\n",
       "   log2_size  \n",
       "0   3.584963  \n",
       "1   3.584963  \n",
       "2   3.584963  \n",
       "3   3.584963  \n",
       "4   3.584963  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(IN_CSV)\n",
    "\n",
    "# normalize column names we use\n",
    "df = df.rename(columns={\n",
    "    \"Benchmark\": \"benchmark\",\n",
    "    \"Method\": \"method\",\n",
    "    \"improve_Test-Acc\": \"improve_Test-Acc\",\n",
    "    \"Val-Acc\": \"val_acc\",\n",
    "    \"Strength\": \"strength\",\n",
    "    \"sample_size\": \"sample_size\",\n",
    "    \"model\": \"model\",\n",
    "    \"seed\": \"seed\"\n",
    "})\n",
    "\n",
    "# keep only what we need\n",
    "need = [\"model\",\"benchmark\",\"method\",\"seed\",\"sample_size\",\"improve_Test-Acc\"]\n",
    "missing = [c for c in need if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "df[\"sample_size\"] = pd.to_numeric(df[\"sample_size\"], errors=\"coerce\")\n",
    "df[\"improve_Test-Acc\"]    = pd.to_numeric(df[\"improve_Test-Acc\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"sample_size\",\"improve_Test-Acc\"]).copy()\n",
    "\n",
    "# Treat seeds as categorical IDs for mixed models\n",
    "df[\"seed\"] = df[\"seed\"].astype(str)\n",
    "\n",
    "# Per-doubling regressor\n",
    "df[\"log2_size\"] = np.log2(df[\"sample_size\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8f072f70-261f-4692-b188-7d35345eb2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log2_size\n",
       "7.228819     2400\n",
       "8.228819     2400\n",
       "6.228819     2400\n",
       "5.584963     2388\n",
       "4.584963     2376\n",
       "9.228819     2156\n",
       "3.584963     2136\n",
       "10.228819    1916\n",
       "11.228819     568\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['log2_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "35b08203-efce-457b-80a5-ee8da8049054",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/tmp/ipykernel_216286/4294889049.py:15: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:955: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>method</th>\n",
       "      <th>n_sample_sizes</th>\n",
       "      <th>n_seeds</th>\n",
       "      <th>n_points</th>\n",
       "      <th>spearman_rho</th>\n",
       "      <th>spearman_p</th>\n",
       "      <th>theilsen_slope_per_doubling</th>\n",
       "      <th>ols_slope_per_doubling</th>\n",
       "      <th>ols_slope_p</th>\n",
       "      <th>ols_slope_ci_lo</th>\n",
       "      <th>ols_slope_ci_hi</th>\n",
       "      <th>ols_r2</th>\n",
       "      <th>ols_aic</th>\n",
       "      <th>mixed_slope_per_doubling</th>\n",
       "      <th>mixed_slope_se</th>\n",
       "      <th>mixed_slope_p_approx</th>\n",
       "      <th>mixed_aic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>118</td>\n",
       "      <td>0.589577</td>\n",
       "      <td>2.154463e-12</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>0.009554</td>\n",
       "      <td>3.806769e-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.315039</td>\n",
       "      <td>-489.468959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>Unsteered</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>iBAS_all</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>118</td>\n",
       "      <td>0.502922</td>\n",
       "      <td>6.485260e-09</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.009966</td>\n",
       "      <td>7.033284e-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.251910</td>\n",
       "      <td>-442.717012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>iBAS_wrong_only</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>118</td>\n",
       "      <td>0.392143</td>\n",
       "      <td>1.124959e-05</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>3.039406e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171929</td>\n",
       "      <td>-501.041057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Deontology</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>120</td>\n",
       "      <td>0.311843</td>\n",
       "      <td>5.259187e-04</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>0.008559</td>\n",
       "      <td>5.820008e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095795</td>\n",
       "      <td>-345.229738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Deontology</td>\n",
       "      <td>Unsteered</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Deontology</td>\n",
       "      <td>iBAS_all</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>120</td>\n",
       "      <td>0.191303</td>\n",
       "      <td>3.634413e-02</td>\n",
       "      <td>0.012784</td>\n",
       "      <td>0.006761</td>\n",
       "      <td>1.838801e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046206</td>\n",
       "      <td>-307.899658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Deontology</td>\n",
       "      <td>iBAS_wrong_only</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>120</td>\n",
       "      <td>0.229729</td>\n",
       "      <td>1.160063e-02</td>\n",
       "      <td>0.012747</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>7.743109e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058570</td>\n",
       "      <td>-295.596399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Justice</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>118</td>\n",
       "      <td>0.482689</td>\n",
       "      <td>3.106167e-08</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>0.008182</td>\n",
       "      <td>1.861849e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.209610</td>\n",
       "      <td>-461.064773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Justice</td>\n",
       "      <td>Unsteered</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       model           benchmark  \\\n",
       "0  NousResearch-Nous-Hermes-2-Mistral-7B-DPO  ETHICS_Commonsense   \n",
       "1  NousResearch-Nous-Hermes-2-Mistral-7B-DPO  ETHICS_Commonsense   \n",
       "2  NousResearch-Nous-Hermes-2-Mistral-7B-DPO  ETHICS_Commonsense   \n",
       "3  NousResearch-Nous-Hermes-2-Mistral-7B-DPO  ETHICS_Commonsense   \n",
       "4  NousResearch-Nous-Hermes-2-Mistral-7B-DPO   ETHICS_Deontology   \n",
       "5  NousResearch-Nous-Hermes-2-Mistral-7B-DPO   ETHICS_Deontology   \n",
       "6  NousResearch-Nous-Hermes-2-Mistral-7B-DPO   ETHICS_Deontology   \n",
       "7  NousResearch-Nous-Hermes-2-Mistral-7B-DPO   ETHICS_Deontology   \n",
       "8  NousResearch-Nous-Hermes-2-Mistral-7B-DPO      ETHICS_Justice   \n",
       "9  NousResearch-Nous-Hermes-2-Mistral-7B-DPO      ETHICS_Justice   \n",
       "\n",
       "            method  n_sample_sizes  n_seeds  n_points  spearman_rho  \\\n",
       "0     BAS_full_mcq               8       15       118      0.589577   \n",
       "1        Unsteered               8       15       118           NaN   \n",
       "2         iBAS_all               8       15       118      0.502922   \n",
       "3  iBAS_wrong_only               8       15       118      0.392143   \n",
       "4     BAS_full_mcq               8       15       120      0.311843   \n",
       "5        Unsteered               8       15       120           NaN   \n",
       "6         iBAS_all               8       15       120      0.191303   \n",
       "7  iBAS_wrong_only               8       15       120      0.229729   \n",
       "8     BAS_full_mcq               8       15       118      0.482689   \n",
       "9        Unsteered               8       15       118           NaN   \n",
       "\n",
       "     spearman_p  theilsen_slope_per_doubling  ols_slope_per_doubling  \\\n",
       "0  2.154463e-12                     0.006540                0.009554   \n",
       "1           NaN                     0.000000                0.000000   \n",
       "2  6.485260e-09                     0.004508                0.009966   \n",
       "3  1.124959e-05                     0.003137                0.006112   \n",
       "4  5.259187e-04                     0.011437                0.008559   \n",
       "5           NaN                     0.000000                0.000000   \n",
       "6  3.634413e-02                     0.012784                0.006761   \n",
       "7  1.160063e-02                     0.012747                0.008065   \n",
       "8  3.106167e-08                     0.004867                0.008182   \n",
       "9           NaN                     0.000000                0.000000   \n",
       "\n",
       "    ols_slope_p  ols_slope_ci_lo  ols_slope_ci_hi    ols_r2     ols_aic  \\\n",
       "0  3.806769e-11              NaN              NaN  0.315039 -489.468959   \n",
       "1           NaN              NaN              NaN       NaN        -inf   \n",
       "2  7.033284e-09              NaN              NaN  0.251910 -442.717012   \n",
       "3  3.039406e-06              NaN              NaN  0.171929 -501.041057   \n",
       "4  5.820008e-04              NaN              NaN  0.095795 -345.229738   \n",
       "5           NaN              NaN              NaN       NaN        -inf   \n",
       "6  1.838801e-02              NaN              NaN  0.046206 -307.899658   \n",
       "7  7.743109e-03              NaN              NaN  0.058570 -295.596399   \n",
       "8  1.861849e-07              NaN              NaN  0.209610 -461.064773   \n",
       "9           NaN              NaN              NaN       NaN        -inf   \n",
       "\n",
       "   mixed_slope_per_doubling  mixed_slope_se  mixed_slope_p_approx  mixed_aic  \n",
       "0                       NaN             NaN                   NaN        NaN  \n",
       "1                       NaN             NaN                   NaN        NaN  \n",
       "2                       NaN             NaN                   NaN        NaN  \n",
       "3                       NaN             NaN                   NaN        NaN  \n",
       "4                       NaN             NaN                   NaN        NaN  \n",
       "5                       NaN             NaN                   NaN        NaN  \n",
       "6                       NaN             NaN                   NaN        NaN  \n",
       "7                       NaN             NaN                   NaN        NaN  \n",
       "8                       NaN             NaN                   NaN        NaN  \n",
       "9                       NaN             NaN                   NaN        NaN  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_cols = [\"model\",\"benchmark\",\"method\"]\n",
    "rows = []\n",
    "\n",
    "for (m, b, meth), g in df.groupby(group_cols):\n",
    "    g = g.dropna(subset=[\"log2_size\",\"improve_Test-Acc\"]).copy()\n",
    "    if g.empty:\n",
    "        continue\n",
    "\n",
    "    n_sizes  = g[\"sample_size\"].nunique()\n",
    "    n_seeds  = g[\"seed\"].nunique()\n",
    "    n_points = g[[\"sample_size\",\"seed\"]].drop_duplicates().shape[0]\n",
    "\n",
    "    # Spearman (monotone trend vs size)\n",
    "    try:\n",
    "        rho, rho_p = spearmanr(g[\"sample_size\"], g[\"improve_Test-Acc\"])\n",
    "    except Exception:\n",
    "        rho, rho_p = np.nan, np.nan\n",
    "\n",
    "    # Theil–Sen (robust) slope on log2_size\n",
    "    ts_slope, ts_intercept = np.nan, np.nan\n",
    "    try:\n",
    "        ts = TheilSenRegressor(random_state=0)\n",
    "        X = g[[\"log2_size\"]].values\n",
    "        y = g[\"improve_Test-Acc\"].values\n",
    "        ts.fit(X, y)\n",
    "        ts_slope = float(ts.coef_[0])       # Δ Test-Acc per doubling\n",
    "        ts_intercept = float(ts.intercept_)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # OLS slope on log2_size (per-doubling effect)\n",
    "    ols_b, ols_p, ols_ci_lo, ols_ci_hi, r2, aic = [np.nan]*6\n",
    "    try:\n",
    "        model_ols = sm.OLS(g[\"improve_Test-Acc\"].values, sm.add_constant(g[\"log2_size\"].values))\n",
    "        res = model_ols.fit()\n",
    "        r2  = res.rsquared\n",
    "        aic = res.aic\n",
    "        ols_b = float(res.params[1])\n",
    "        ols_p = float(res.pvalues[1])\n",
    "        ci_lo, ci_hi = res.conf_int().iloc[1]\n",
    "        ols_ci_lo, ols_ci_hi = float(ci_lo), float(ci_hi)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Mixed-effects: random intercepts for seed; fixed slope on log2_size (if possible)\n",
    "    mx_b, mx_p, mx_se, mx_aic = [np.nan]*4\n",
    "    if n_seeds >= 2 and n_sizes >= 2:\n",
    "        try:\n",
    "            mx = smf.mixedlm(\"improve_Test-Acc ~ log2_size\", g, groups=g[\"seed\"])\n",
    "            mx_res = mx.fit(method=\"lbfgs\", maxiter=500, reml=True, disp=False)\n",
    "            if \"log2_size\" in mx_res.params.index:\n",
    "                from scipy.stats import norm\n",
    "                mx_b  = float(mx_res.params[\"log2_size\"])\n",
    "                mx_se = float(mx_res.bse[\"log2_size\"])\n",
    "                # Wald z, two-sided p via normal approx\n",
    "                z = float(mx_res.tvalues[\"log2_size\"])\n",
    "                mx_p = float(2 * (1 - norm.cdf(abs(z))))\n",
    "                mx_aic = float(mx_res.aic)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": m, \"benchmark\": b, \"method\": meth,\n",
    "        \"n_sample_sizes\": n_sizes,\n",
    "        \"n_seeds\": n_seeds,\n",
    "        \"n_points\": n_points,\n",
    "        \"spearman_rho\": rho, \"spearman_p\": rho_p,\n",
    "        \"theilsen_slope_per_doubling\": ts_slope,\n",
    "        \"ols_slope_per_doubling\": ols_b,\n",
    "        \"ols_slope_p\": ols_p,\n",
    "        \"ols_slope_ci_lo\": ols_ci_lo, \"ols_slope_ci_hi\": ols_ci_hi,\n",
    "        \"ols_r2\": r2, \"ols_aic\": aic,\n",
    "        \"mixed_slope_per_doubling\": mx_b,\n",
    "        \"mixed_slope_se\": mx_se,\n",
    "        \"mixed_slope_p_approx\": mx_p,\n",
    "        \"mixed_aic\": mx_aic,\n",
    "    })\n",
    "\n",
    "per_group = pd.DataFrame(rows).sort_values(group_cols)\n",
    "per_group_path = OUT_DIR / \"per_group_summary.csv\"\n",
    "per_group.to_csv(per_group_path, index=False)\n",
    "per_group.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ce37505e-6f48-409c-9788-66f8efce6615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>method</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>improve_mean</th>\n",
       "      <th>improve_std</th>\n",
       "      <th>n</th>\n",
       "      <th>improve_stderr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.033696</td>\n",
       "      <td>0.053105</td>\n",
       "      <td>13</td>\n",
       "      <td>0.014729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.030038</td>\n",
       "      <td>0.025214</td>\n",
       "      <td>15</td>\n",
       "      <td>0.006510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>48</td>\n",
       "      <td>-0.009583</td>\n",
       "      <td>0.029031</td>\n",
       "      <td>15</td>\n",
       "      <td>0.007496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>75</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.035474</td>\n",
       "      <td>15</td>\n",
       "      <td>0.009159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>150</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.020915</td>\n",
       "      <td>15</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>300</td>\n",
       "      <td>0.018917</td>\n",
       "      <td>0.026002</td>\n",
       "      <td>15</td>\n",
       "      <td>0.006714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>600</td>\n",
       "      <td>0.022917</td>\n",
       "      <td>0.020829</td>\n",
       "      <td>15</td>\n",
       "      <td>0.005378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>BAS_full_mcq</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.023363</td>\n",
       "      <td>0.022640</td>\n",
       "      <td>15</td>\n",
       "      <td>0.005846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>Unsteered</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NousResearch-Nous-Hermes-2-Mistral-7B-DPO</td>\n",
       "      <td>ETHICS_Commonsense</td>\n",
       "      <td>Unsteered</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       model           benchmark  \\\n",
       "0  NousResearch-Nous-Hermes-2-Mistral-7B-DPO  ETHICS_Commonsense   \n",
       "1  NousResearch-Nous-Hermes-2-Mistral-7B-DPO  ETHICS_Commonsense   \n",
       "2  NousResearch-Nous-Hermes-2-Mistral-7B-DPO  ETHICS_Commonsense   \n",
       "3  NousResearch-Nous-Hermes-2-Mistral-7B-DPO  ETHICS_Commonsense   \n",
       "4  NousResearch-Nous-Hermes-2-Mistral-7B-DPO  ETHICS_Commonsense   \n",
       "5  NousResearch-Nous-Hermes-2-Mistral-7B-DPO  ETHICS_Commonsense   \n",
       "6  NousResearch-Nous-Hermes-2-Mistral-7B-DPO  ETHICS_Commonsense   \n",
       "7  NousResearch-Nous-Hermes-2-Mistral-7B-DPO  ETHICS_Commonsense   \n",
       "8  NousResearch-Nous-Hermes-2-Mistral-7B-DPO  ETHICS_Commonsense   \n",
       "9  NousResearch-Nous-Hermes-2-Mistral-7B-DPO  ETHICS_Commonsense   \n",
       "\n",
       "         method  sample_size  improve_mean  improve_std   n  improve_stderr  \n",
       "0  BAS_full_mcq           12     -0.033696     0.053105  13        0.014729  \n",
       "1  BAS_full_mcq           24     -0.030038     0.025214  15        0.006510  \n",
       "2  BAS_full_mcq           48     -0.009583     0.029031  15        0.007496  \n",
       "3  BAS_full_mcq           75      0.000500     0.035474  15        0.009159  \n",
       "4  BAS_full_mcq          150      0.011667     0.020915  15        0.005400  \n",
       "5  BAS_full_mcq          300      0.018917     0.026002  15        0.006714  \n",
       "6  BAS_full_mcq          600      0.022917     0.020829  15        0.005378  \n",
       "7  BAS_full_mcq         1200      0.023363     0.022640  15        0.005846  \n",
       "8     Unsteered           12      0.000000     0.000000  13        0.000000  \n",
       "9     Unsteered           24      0.000000     0.000000  15        0.000000  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg = (\n",
    "    df.groupby(group_cols + [\"sample_size\"], as_index=False)\n",
    "      .agg(improve_mean=(\"improve_Test-Acc\",\"mean\"),\n",
    "           improve_std =(\"improve_Test-Acc\",\"std\"),\n",
    "           n=(\"improve_Test-Acc\",\"count\"))\n",
    ")\n",
    "agg[\"improve_stderr\"] = agg[\"improve_std\"] / np.sqrt(agg[\"n\"].clip(lower=1))\n",
    "\n",
    "agg_path = OUT_DIR / \"per_size_agg.csv\"\n",
    "agg.to_csv(agg_path, index=False)\n",
    "agg.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8509ce1a-e65b-4392-a8a3-bcfba59e1176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample_size\n",
       "12      160\n",
       "24      160\n",
       "48      160\n",
       "75      160\n",
       "150     160\n",
       "300     160\n",
       "600     160\n",
       "1200    160\n",
       "2400     40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg['sample_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f1201a71-474c-4a0f-9f06-54da2534dfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model kind: mixedlm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:1634: UserWarning: Random effects covariance is singular\n",
      "  warnings.warn(msg)\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2054: UserWarning: The random effects covariance matrix is singular.\n",
      "  warnings.warn(_warn_cov_sing)\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2245: UserWarning: The random effects covariance matrix is singular.\n",
      "  warnings.warn(_warn_cov_sing)\n",
      "/home/zc362/.conda/envs/llm-gpu-clean/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>se</th>\n",
       "      <th>t_or_z</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-5.564527e-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(model)[T.TinyLlama-TinyLlama-1.1B-Chat-v1.0]</th>\n",
       "      <td>1.673569e-02</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>2.896873</td>\n",
       "      <td>3.769022e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(model)[T.deepseek-ai-DeepSeek-R1-Distill-Llama-8B]</th>\n",
       "      <td>1.217753e-02</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>2.400365</td>\n",
       "      <td>1.637873e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(model)[T.meta-llama-Llama-3.1-8B-Instruct]</th>\n",
       "      <td>2.116286e-03</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.390788</td>\n",
       "      <td>6.959539e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(method)[T.Unsteered]</th>\n",
       "      <td>-2.470571e-02</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>-4.683837</td>\n",
       "      <td>2.815534e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(method)[T.iBAS_all]</th>\n",
       "      <td>1.866255e-03</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.353814</td>\n",
       "      <td>7.234780e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(method)[T.iBAS_wrong_only]</th>\n",
       "      <td>1.415688e-02</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>2.683935</td>\n",
       "      <td>7.276134e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(benchmark)[T.ETHICS_Deontology]</th>\n",
       "      <td>3.904769e-02</td>\n",
       "      <td>0.008352</td>\n",
       "      <td>4.674999</td>\n",
       "      <td>2.939557e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(benchmark)[T.ETHICS_Justice]</th>\n",
       "      <td>-1.362708e-03</td>\n",
       "      <td>0.008254</td>\n",
       "      <td>-0.165100</td>\n",
       "      <td>8.688650e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(benchmark)[T.GenderIdentity]</th>\n",
       "      <td>8.525510e-03</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>1.025515</td>\n",
       "      <td>3.051201e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(benchmark)[T.Nationality]</th>\n",
       "      <td>9.459727e-03</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>1.127460</td>\n",
       "      <td>2.595481e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(benchmark)[T.RaceEthnicity]</th>\n",
       "      <td>1.478713e-02</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>1.780476</td>\n",
       "      <td>7.499809e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(benchmark)[T.RaceXGender]</th>\n",
       "      <td>1.927014e-02</td>\n",
       "      <td>0.008320</td>\n",
       "      <td>2.316262</td>\n",
       "      <td>2.054400e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(benchmark)[T.RaceXSES]</th>\n",
       "      <td>1.447976e-02</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>1.749208</td>\n",
       "      <td>8.025508e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(benchmark)[T.SES]</th>\n",
       "      <td>1.409091e-02</td>\n",
       "      <td>0.008349</td>\n",
       "      <td>1.687806</td>\n",
       "      <td>9.144845e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(benchmark)[T.Sycophancy]</th>\n",
       "      <td>3.442945e-01</td>\n",
       "      <td>0.008328</td>\n",
       "      <td>41.344170</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log2_size</th>\n",
       "      <td>8.951433e-03</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>8.685978</td>\n",
       "      <td>3.754978e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(model)[T.TinyLlama-TinyLlama-1.1B-Chat-v1.0]:log2_size</th>\n",
       "      <td>-6.216347e-03</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>-7.416088</td>\n",
       "      <td>1.206300e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(model)[T.deepseek-ai-DeepSeek-R1-Distill-Llama-8B]:log2_size</th>\n",
       "      <td>-4.415162e-03</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>-6.475051</td>\n",
       "      <td>9.477965e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(model)[T.meta-llama-Llama-3.1-8B-Instruct]:log2_size</th>\n",
       "      <td>-5.395491e-04</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>-0.720371</td>\n",
       "      <td>4.712967e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        coef  \\\n",
       "Intercept                                                      -5.564527e-14   \n",
       "C(model)[T.TinyLlama-TinyLlama-1.1B-Chat-v1.0]                  1.673569e-02   \n",
       "C(model)[T.deepseek-ai-DeepSeek-R1-Distill-Llama-8B]            1.217753e-02   \n",
       "C(model)[T.meta-llama-Llama-3.1-8B-Instruct]                    2.116286e-03   \n",
       "C(method)[T.Unsteered]                                         -2.470571e-02   \n",
       "C(method)[T.iBAS_all]                                           1.866255e-03   \n",
       "C(method)[T.iBAS_wrong_only]                                    1.415688e-02   \n",
       "C(benchmark)[T.ETHICS_Deontology]                               3.904769e-02   \n",
       "C(benchmark)[T.ETHICS_Justice]                                 -1.362708e-03   \n",
       "C(benchmark)[T.GenderIdentity]                                  8.525510e-03   \n",
       "C(benchmark)[T.Nationality]                                     9.459727e-03   \n",
       "C(benchmark)[T.RaceEthnicity]                                   1.478713e-02   \n",
       "C(benchmark)[T.RaceXGender]                                     1.927014e-02   \n",
       "C(benchmark)[T.RaceXSES]                                        1.447976e-02   \n",
       "C(benchmark)[T.SES]                                             1.409091e-02   \n",
       "C(benchmark)[T.Sycophancy]                                      3.442945e-01   \n",
       "log2_size                                                       8.951433e-03   \n",
       "C(model)[T.TinyLlama-TinyLlama-1.1B-Chat-v1.0]:log2_size       -6.216347e-03   \n",
       "C(model)[T.deepseek-ai-DeepSeek-R1-Distill-Llama-8B]:log2_size -4.415162e-03   \n",
       "C(model)[T.meta-llama-Llama-3.1-8B-Instruct]:log2_size         -5.395491e-04   \n",
       "\n",
       "                                                                      se  \\\n",
       "Intercept                                                            NaN   \n",
       "C(model)[T.TinyLlama-TinyLlama-1.1B-Chat-v1.0]                  0.005777   \n",
       "C(model)[T.deepseek-ai-DeepSeek-R1-Distill-Llama-8B]            0.005073   \n",
       "C(model)[T.meta-llama-Llama-3.1-8B-Instruct]                    0.005415   \n",
       "C(method)[T.Unsteered]                                          0.005275   \n",
       "C(method)[T.iBAS_all]                                           0.005275   \n",
       "C(method)[T.iBAS_wrong_only]                                    0.005275   \n",
       "C(benchmark)[T.ETHICS_Deontology]                               0.008352   \n",
       "C(benchmark)[T.ETHICS_Justice]                                  0.008254   \n",
       "C(benchmark)[T.GenderIdentity]                                  0.008313   \n",
       "C(benchmark)[T.Nationality]                                     0.008390   \n",
       "C(benchmark)[T.RaceEthnicity]                                   0.008305   \n",
       "C(benchmark)[T.RaceXGender]                                     0.008320   \n",
       "C(benchmark)[T.RaceXSES]                                        0.008278   \n",
       "C(benchmark)[T.SES]                                             0.008349   \n",
       "C(benchmark)[T.Sycophancy]                                      0.008328   \n",
       "log2_size                                                       0.001031   \n",
       "C(model)[T.TinyLlama-TinyLlama-1.1B-Chat-v1.0]:log2_size        0.000838   \n",
       "C(model)[T.deepseek-ai-DeepSeek-R1-Distill-Llama-8B]:log2_size  0.000682   \n",
       "C(model)[T.meta-llama-Llama-3.1-8B-Instruct]:log2_size          0.000749   \n",
       "\n",
       "                                                                   t_or_z  \\\n",
       "Intercept                                                             NaN   \n",
       "C(model)[T.TinyLlama-TinyLlama-1.1B-Chat-v1.0]                   2.896873   \n",
       "C(model)[T.deepseek-ai-DeepSeek-R1-Distill-Llama-8B]             2.400365   \n",
       "C(model)[T.meta-llama-Llama-3.1-8B-Instruct]                     0.390788   \n",
       "C(method)[T.Unsteered]                                          -4.683837   \n",
       "C(method)[T.iBAS_all]                                            0.353814   \n",
       "C(method)[T.iBAS_wrong_only]                                     2.683935   \n",
       "C(benchmark)[T.ETHICS_Deontology]                                4.674999   \n",
       "C(benchmark)[T.ETHICS_Justice]                                  -0.165100   \n",
       "C(benchmark)[T.GenderIdentity]                                   1.025515   \n",
       "C(benchmark)[T.Nationality]                                      1.127460   \n",
       "C(benchmark)[T.RaceEthnicity]                                    1.780476   \n",
       "C(benchmark)[T.RaceXGender]                                      2.316262   \n",
       "C(benchmark)[T.RaceXSES]                                         1.749208   \n",
       "C(benchmark)[T.SES]                                              1.687806   \n",
       "C(benchmark)[T.Sycophancy]                                      41.344170   \n",
       "log2_size                                                        8.685978   \n",
       "C(model)[T.TinyLlama-TinyLlama-1.1B-Chat-v1.0]:log2_size        -7.416088   \n",
       "C(model)[T.deepseek-ai-DeepSeek-R1-Distill-Llama-8B]:log2_size  -6.475051   \n",
       "C(model)[T.meta-llama-Llama-3.1-8B-Instruct]:log2_size          -0.720371   \n",
       "\n",
       "                                                                     p_value  \n",
       "Intercept                                                                NaN  \n",
       "C(model)[T.TinyLlama-TinyLlama-1.1B-Chat-v1.0]                  3.769022e-03  \n",
       "C(model)[T.deepseek-ai-DeepSeek-R1-Distill-Llama-8B]            1.637873e-02  \n",
       "C(model)[T.meta-llama-Llama-3.1-8B-Instruct]                    6.959539e-01  \n",
       "C(method)[T.Unsteered]                                          2.815534e-06  \n",
       "C(method)[T.iBAS_all]                                           7.234780e-01  \n",
       "C(method)[T.iBAS_wrong_only]                                    7.276134e-03  \n",
       "C(benchmark)[T.ETHICS_Deontology]                               2.939557e-06  \n",
       "C(benchmark)[T.ETHICS_Justice]                                  8.688650e-01  \n",
       "C(benchmark)[T.GenderIdentity]                                  3.051201e-01  \n",
       "C(benchmark)[T.Nationality]                                     2.595481e-01  \n",
       "C(benchmark)[T.RaceEthnicity]                                   7.499809e-02  \n",
       "C(benchmark)[T.RaceXGender]                                     2.054400e-02  \n",
       "C(benchmark)[T.RaceXSES]                                        8.025508e-02  \n",
       "C(benchmark)[T.SES]                                             9.144845e-02  \n",
       "C(benchmark)[T.Sycophancy]                                      0.000000e+00  \n",
       "log2_size                                                       3.754978e-18  \n",
       "C(model)[T.TinyLlama-TinyLlama-1.1B-Chat-v1.0]:log2_size        1.206300e-13  \n",
       "C(model)[T.deepseek-ai-DeepSeek-R1-Distill-Llama-8B]:log2_size  9.477965e-11  \n",
       "C(model)[T.meta-llama-Llama-3.1-8B-Instruct]:log2_size          4.712967e-01  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A tractable global spec: baseline slope + modifiers by model/method/benchmark.\n",
    "# Random intercepts for seed if possible; else OLS fallback.\n",
    "formula = \"Q('improve_Test-Acc')~ log2_size + C(model)*log2_size + C(method)*log2_size + C(benchmark)*log2_size\"\n",
    "\n",
    "def fit_global(formula, data):\n",
    "    try:\n",
    "        mx = smf.mixedlm(formula, data, groups=data[\"seed\"])\n",
    "        res = mx.fit(method=\"lbfgs\", maxiter=1000, reml=True, disp=False)\n",
    "        return res, \"mixedlm\"\n",
    "    except Exception:\n",
    "        ols = smf.ols(formula, data=data).fit()\n",
    "        return ols, \"ols\"\n",
    "\n",
    "global_fit, kind = fit_global(formula, df)\n",
    "print(\"Global model kind:\", kind)\n",
    "\n",
    "coefs = pd.DataFrame({\n",
    "    \"coef\": global_fit.params,\n",
    "    \"se\": getattr(global_fit, \"bse\", pd.Series(index=global_fit.params.index, dtype=float)),\n",
    "    \"t_or_z\": getattr(global_fit, \"tvalues\", pd.Series(index=global_fit.params.index, dtype=float)),\n",
    "    \"p_value\": getattr(global_fit, \"pvalues\", pd.Series(index=global_fit.params.index, dtype=float)),\n",
    "})\n",
    "try:\n",
    "    coefs.attrs[\"AIC\"] = float(global_fit.aic)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "coefs_path = OUT_DIR / \"global_mixed_model_coefs.csv\"\n",
    "coefs.to_csv(coefs_path)\n",
    "coefs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fa5de83e-841d-40ae-9243-282088d76d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('sample_size_analysis/figures/meta-llama-Llama-3.1-8B-Instruct__RaceXGender__BAS_full_mcq.png'),\n",
       " PosixPath('sample_size_analysis/figures/NousResearch-Nous-Hermes-2-Mistral-7B-DPO__RaceXGender__iBAS_all.png'),\n",
       " PosixPath('sample_size_analysis/figures/NousResearch-Nous-Hermes-2-Mistral-7B-DPO__RaceEthnicity__BAS_full_mcq.png'),\n",
       " PosixPath('sample_size_analysis/figures/TinyLlama-TinyLlama-1.1B-Chat-v1.0__Sycophancy__iBAS_wrong_only.png'),\n",
       " PosixPath('sample_size_analysis/figures/NousResearch-Nous-Hermes-2-Mistral-7B-DPO__RaceXGender__iBAS_wrong_only.png')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_panel(a, model, benchmark, method, save_dir=FIG_DIR):\n",
    "    sub = a.query(\"model == @model and benchmark == @benchmark and method == @method\").copy()\n",
    "    if sub.empty: \n",
    "        return None\n",
    "    sub = sub.sort_values(\"sample_size\")\n",
    "    plt.figure()\n",
    "    plt.errorbar(\n",
    "        sub[\"sample_size\"], \n",
    "        sub[\"improve_mean\"],                # mean improvement\n",
    "        yerr=sub[\"improve_stderr\"],         # standard error of improvement\n",
    "        fmt=\"o-\", capsize=3\n",
    "    )\n",
    "    plt.xscale(\"log\", base=2)\n",
    "    plt.xlabel(\"sample_size (log₂ scale)\")\n",
    "    plt.ylabel(\"Improve-Test-Acc (mean ± s.e.)\")\n",
    "    plt.title(f\"{model} | {benchmark} | {method}\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    fname = f\"{model}__{benchmark}__{method}.png\".replace(\"/\", \"_\")\n",
    "    plt.tight_layout()\n",
    "    path = save_dir / fname\n",
    "    plt.savefig(path, dpi=150)\n",
    "    plt.close()\n",
    "    return path\n",
    "\n",
    "top = (\n",
    "    per_group.dropna(subset=[\"ols_slope_per_doubling\"])\n",
    "             .assign(abs_slope=lambda x: x[\"ols_slope_per_doubling\"].abs())\n",
    "             .sort_values(\"abs_slope\", ascending=False)\n",
    ")\n",
    "made = []\n",
    "for _, r in top.head(12).iterrows():\n",
    "    p = plot_panel(agg, r[\"model\"], r[\"benchmark\"], r[\"method\"])\n",
    "    if p: made.append(p)\n",
    "\n",
    "made[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bde7cee1-b1e5-44de-af48-ed9dcb596078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('sample_size_analysis/figures/slope_distribution.png')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "valid = per_group[\"ols_slope_per_doubling\"].dropna()\n",
    "plt.hist(valid, bins=30)\n",
    "plt.axvline(valid.mean(), linestyle=\"--\")\n",
    "plt.title(\"Δ Test-Acc per doubling of sample_size (OLS slopes)\")\n",
    "plt.xlabel(\"per-doubling slope\")\n",
    "plt.ylabel(\"count\")\n",
    "path = FIG_DIR / \"slope_distribution.png\"\n",
    "plt.tight_layout(); plt.savefig(path, dpi=150); plt.close()\n",
    "path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2fff3957-5901-42e9-b5d1-ccec7567706c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<h3>Artifacts</h3>\n",
       "<ul>\n",
       "  <li><code>sample_size_analysis/per_group_summary.csv</code> — one row per (model × benchmark × method)\n",
       "    <ul>\n",
       "      <li><b>ols_slope_per_doubling</b> (+ CI & p): Δ Test-Acc per doubling of sample size</li>\n",
       "      <li><b>spearman_rho</b>/<b>spearman_p</b>: monotone trend evidence</li>\n",
       "      <li><b>theilsen_slope_per_doubling</b>: robust median slope</li>\n",
       "      <li><b>mixed_slope_per_doubling</b>: slope w/ random intercepts for seed (if fit)</li>\n",
       "    </ul>\n",
       "  </li>\n",
       "  <li><code>sample_size_analysis/per_size_agg.csv</code> — per sample_size mean/SD/SE for plotting</li>\n",
       "  <li><code>sample_size_analysis/global_mixed_model_coefs.csv</code> — global model fixed effects (baseline + modifiers)</li>\n",
       "  <li>Figures in <code>sample_size_analysis/figures</code></li>\n",
       "</ul>\n",
       "<p><i>Interpretation tip:</i> coefficient on <code>log2_size</code> ≈ change in Test-Acc for a 2× increase in sample_size.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(f\"\"\"\n",
    "<h3>Artifacts</h3>\n",
    "<ul>\n",
    "  <li><code>{per_group_path}</code> — one row per (model × benchmark × method)\n",
    "    <ul>\n",
    "      <li><b>ols_slope_per_doubling</b> (+ CI & p): Δ Test-Acc per doubling of sample size</li>\n",
    "      <li><b>spearman_rho</b>/<b>spearman_p</b>: monotone trend evidence</li>\n",
    "      <li><b>theilsen_slope_per_doubling</b>: robust median slope</li>\n",
    "      <li><b>mixed_slope_per_doubling</b>: slope w/ random intercepts for seed (if fit)</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li><code>{agg_path}</code> — per sample_size mean/SD/SE for plotting</li>\n",
    "  <li><code>{coefs_path}</code> — global model fixed effects (baseline + modifiers)</li>\n",
    "  <li>Figures in <code>{FIG_DIR}</code></li>\n",
    "</ul>\n",
    "<p><i>Interpretation tip:</i> coefficient on <code>log2_size</code> ≈ change in Test-Acc for a 2× increase in sample_size.</p>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62318050-2ebc-42f5-badb-c5b3a73fa31e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
